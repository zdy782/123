{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Analyzing the results for `finetuning_num_genes`\n",
    "\n",
    "This is part 1, the results of sweeping all hyperparameter for rdkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import seml\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "matplotlib.style.use(\"fivethirtyeight\")\n",
    "matplotlib.style.use(\"seaborn-talk\")\n",
    "matplotlib.rcParams['font.family'] = \"monospace\"\n",
    "plt.rcParams['savefig.facecolor'] = 'white'\n",
    "sns.set_context(\"poster\")\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "results = seml.get_results(\n",
    "    \"finetuning_num_genes\",\n",
    "    to_data_frame=True,\n",
    "    fields=[\"config\", \"result\", \"seml\", \"config_hash\"],\n",
    "    states=[\"COMPLETED\"],\n",
    "    filter_dict={\n",
    "        \"batch_id\": 3, \n",
    "        'config.dataset.data_params.split_key': 'split_ood_finetuning', # split_ood_finetuning, split_random, split_ho_pathway, split_ho_epigenetic, split_ho_epigenetic_all\n",
    "        'config.model.append_ae_layer': False,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Look at number of experiments per model\n",
    "results[\"config.model.embedding.model\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pd.crosstab(\n",
    "    results['config.model.embedding.model'],\n",
    "    results['result.perturbation disentanglement'].isnull()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "[c for c in results.columns if 'ae' in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pd.crosstab(\n",
    "    results['config.dataset.data_params.split_key'],\n",
    "    results['config.model.load_pretrained']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pd.crosstab(\n",
    "    results['config.dataset.data_params.split_key'],\n",
    "    results['result.loss_reconstruction'].isnull()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# columns\n",
    "results.isnull().any()[results.isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# rows without nans \n",
    "clean_id = results.loc[~results['result.training'].isnull(), '_id']\n",
    "# clean_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Preprocessing the results dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# percentage of training runs that resulted in NaNs or totally failed\n",
    "\n",
    "results_clean = results[results._id.isin(clean_id)].copy()\n",
    "print(f\"Percentage of invalid (nan) runs: {1 - len(clean_id) / len(results)}\")\n",
    "\n",
    "# Remove runs with r2 < 0.6 on the training set\n",
    "# results_clean = results_clean[results_clean['result.training'].apply(lambda x: x[0][0])>0.6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "results_clean[\"config.model.embedding.model\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "results_clean[['config.model.load_pretrained', 'result.test_sc', 'config.model.append_ae_layer', \"result.ood\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# calculate some stats\n",
    "get_mean = lambda x: np.array(x)[-1, 0]\n",
    "get_mean_de = lambda x: np.array(x)[-1, 1]\n",
    "\n",
    "results_clean[\"result.training_mean\"] = results_clean[\"result.training\"].apply(get_mean)\n",
    "results_clean[\"result.training_mean_de\"] = results_clean[\"result.training\"].apply(get_mean_de)\n",
    "results_clean[\"result.val_mean\"] = results_clean[\"result.test\"].apply(get_mean)\n",
    "results_clean[\"result.val_mean_de\"] = results_clean[\"result.test\"].apply(get_mean_de)\n",
    "results_clean[\"result.test_mean\"] = results_clean[\"result.ood\"].apply(get_mean)\n",
    "results_clean[\"result.test_mean_de\"] = results_clean[\"result.ood\"].apply(get_mean_de)\n",
    "results_clean[\"result.perturbation disentanglement\"] = results_clean[\"result.perturbation disentanglement\"].apply(lambda x: x[0])\n",
    "results_clean[\"result.covariate disentanglement\"] = results_clean[\"result.covariate disentanglement\"].apply(lambda x: x[0][0])\n",
    "results_clean[\"result.final_reconstruction\"] = results_clean[\"result.loss_reconstruction\"].apply(lambda x: x[-1])\n",
    "\n",
    "results_clean.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "results_clean[\"result.training_sc_mean\"] = results_clean[\"result.training_sc\"].apply(get_mean)\n",
    "results_clean[\"result.training_sc_mean_de\"] = results_clean[\"result.training_sc\"].apply(get_mean_de)\n",
    "results_clean[\"result.val_sc_mean\"] = results_clean[\"result.test_sc\"].apply(get_mean)\n",
    "results_clean[\"result.val_sc_mean_de\"] = results_clean[\"result.test_sc\"].apply(get_mean_de)\n",
    "results_clean[\"result.test_sc_mean\"] = results_clean[\"result.ood_sc\"].apply(get_mean)\n",
    "results_clean[\"result.test_sc_mean_de\"] = results_clean[\"result.ood_sc\"].apply(get_mean_de)\n",
    "\n",
    "results_clean = results_clean[results_clean[\"result.val_sc_mean\"] > 0.01]\n",
    "results_clean = results_clean[results_clean[\"result.val_mean_de\"] > 0.4]\n",
    "# results_clean = results_clean[results_clean[\"config.model.append_ae_layer\"] == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Look at early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,1)\n",
    "sns.histplot(data=results_clean[results_clean['config.model.load_pretrained']==True][\"result.epoch\"].apply(max), ax=ax[0])\n",
    "ax[0].set_title(\"Total epochs before final stopping (min 125), pretrained\")\n",
    "\n",
    "ax[1] = sns.histplot(data=results_clean[results_clean['config.model.load_pretrained']==False][\"result.epoch\"].apply(max), ax=ax[1])\n",
    "ax[1].set_title(\"Total epochs before final stopping (min 125), non pretrained\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Look at $r^2$ reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "[c for c in results_clean.columns if 'pretrain' in c]\n",
    "\n",
    "results_clean[[\"config.model.embedding.model\", 'config.model.load_pretrained', 'config.model.append_ae_layer']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### DE genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# DE genes\n",
    "rows, cols = 1, 3\n",
    "fig, ax = plt.subplots(rows, cols, figsize=(10*cols,6*rows))\n",
    "\n",
    "for i, y in enumerate((\"result.training_mean_de\", \"result.val_mean_de\", \"result.test_mean_de\")):\n",
    "    sns.violinplot(\n",
    "        data=results_clean, \n",
    "        x=\"config.model.embedding.model\", \n",
    "        y=y, \n",
    "        hue='config.model.load_pretrained', \n",
    "        inner='points', \n",
    "        ax=ax[i], \n",
    "        scale='width',\n",
    "        )\n",
    "    # ax[i].set_ylim([0.3,1.01])\n",
    "    ax[i].set_xticklabels(ax[i].get_xticklabels(), rotation=75, ha='right')\n",
    "    ax[i].set_xlabel('')\n",
    "    ax[i].set_ylabel(y.split('.')[-1])\n",
    "    ax[i].legend(title='Pretrained',loc='lower right', fontsize=18, title_fontsize=24)\n",
    "\n",
    "ax[0].get_legend().remove()\n",
    "ax[1].get_legend().remove()\n",
    "ax[2].legend(title='Pretrained', fontsize=18, title_fontsize=24, loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# DE genes\n",
    "rows, cols = 1, 3\n",
    "fig, ax = plt.subplots(rows, cols, figsize=(10*cols,6*rows))\n",
    "\n",
    "for i, y in enumerate((\"result.training_sc_mean_de\", \"result.val_sc_mean_de\", \"result.test_sc_mean_de\")):\n",
    "    sns.violinplot(\n",
    "        data=results_clean, \n",
    "        x=\"config.model.embedding.model\", \n",
    "        y=y, \n",
    "        hue='config.model.load_pretrained', \n",
    "        inner='points', \n",
    "        ax=ax[i], \n",
    "        scale='width',\n",
    "        )\n",
    "    ax[i].set_ylim([0.0,0.5])\n",
    "    ax[i].set_xticklabels(ax[i].get_xticklabels(), rotation=75, ha='right')\n",
    "    ax[i].set_xlabel('')\n",
    "    ax[i].set_ylabel(y.split('.')[-1])\n",
    "    ax[i].legend(title='Pretrained',loc='lower right', fontsize=18, title_fontsize=24)\n",
    "\n",
    "ax[0].get_legend().remove()\n",
    "ax[1].get_legend().remove()\n",
    "ax[2].legend(title='Pretrained', fontsize=18, title_fontsize=24, loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### All genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# DE genes\n",
    "rows, cols = 1, 3\n",
    "fig, ax = plt.subplots(rows, cols, figsize=(10*cols,6*rows))\n",
    "\n",
    "for i, y in enumerate((\"result.training_mean\", \"result.val_mean\", \"result.test_mean\")):\n",
    "    sns.violinplot(\n",
    "        data=results_clean, \n",
    "        x=\"config.model.embedding.model\", \n",
    "        y=y, \n",
    "        hue='config.model.load_pretrained', \n",
    "        inner='points', \n",
    "        ax=ax[i], \n",
    "        scale='width',\n",
    "        )\n",
    "    # ax[i].set_ylim([0.3,1.01])\n",
    "    ax[i].set_xticklabels(ax[i].get_xticklabels(), rotation=75, ha='right')\n",
    "    ax[i].set_xlabel('')\n",
    "    ax[i].set_ylabel(y.split('.')[-1])\n",
    "    ax[i].legend(title='Pretrained',loc='lower right', fontsize=18, title_fontsize=24)\n",
    "\n",
    "ax[0].get_legend().remove()\n",
    "ax[1].get_legend().remove()\n",
    "ax[2].legend(title='Pretrained', fontsize=18, title_fontsize=24, loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Look at disentanglement scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rows = 2 \n",
    "cols = 1\n",
    "fig, ax = plt.subplots(rows, cols, figsize=(10*cols, 7*rows), sharex=True)\n",
    "\n",
    "max_entangle = [0.1, 0.8]\n",
    "for i, y in enumerate([\"result.perturbation disentanglement\", \"result.covariate disentanglement\"]):\n",
    "    sns.violinplot(data=results_clean, x=\"config.model.embedding.model\", y=y, inner='point' ,ax=ax[i], hue=\"config.model.load_pretrained\")\n",
    "    # ax[i].set_ylim([0,1])\n",
    "    ax[i].set_xticklabels(ax[i].get_xticklabels(), rotation=75, ha='right')\n",
    "    ax[i].axhline(max_entangle[i],ls=':', color='black')\n",
    "    ax[i].set_xlabel('')\n",
    "    ax[i].set_ylabel(y.split('.')[-1])\n",
    "ax[0].get_legend().remove()\n",
    "ax[1].legend(title='Pretrained', fontsize=18, title_fontsize=24, loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Subselect to disentangled models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_top = 2\n",
    "def performance_condition(emb, pretrained, max_entangle, max_entangle_cov): \n",
    "    cond = results_clean[\"config.model.embedding.model\"] == emb\n",
    "    cond = cond & (results_clean[\"result.perturbation disentanglement\"] < max_entangle) \n",
    "    cond = cond & (results_clean[\"result.covariate disentanglement\"] < max_entangle_cov) \n",
    "    cond = cond & (results_clean[\"config.model.load_pretrained\"] == pretrained)\n",
    "    return cond\n",
    "\n",
    "best = []\n",
    "for embedding in list(results_clean[\"config.model.embedding.model\"].unique()):\n",
    "    for pretrained in [True, False]:\n",
    "        df = results_clean[performance_condition(embedding, pretrained, 0.1, 1)]\n",
    "        print(embedding, pretrained, len(df))\n",
    "        best.append(df.sort_values(by=\"result.val_mean_de\", ascending=False).head(n_top))\n",
    "\n",
    "best = pd.concat(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# All genes, DE genes, disentanglement\n",
    "rows, cols = 1, 4\n",
    "fig, ax = plt.subplots(rows, cols, figsize=(10*cols,6*rows))\n",
    "\n",
    "for i, y in enumerate([\"result.test_mean\", \"result.test_mean_de\", \"result.perturbation disentanglement\", \"result.covariate disentanglement\"]):\n",
    "    sns.violinplot(\n",
    "        data=best, \n",
    "        x=\"config.model.embedding.model\", \n",
    "        y=y, \n",
    "        hue='config.model.load_pretrained', \n",
    "        inner='points', \n",
    "        ax=ax[i], \n",
    "        scale='width',\n",
    "        )\n",
    "    ax[i].set_xticklabels(ax[i].get_xticklabels(), rotation=75, ha='right')\n",
    "    ax[i].set_xlabel('')\n",
    "    ax[i].set_ylabel(y.split('.')[-1])\n",
    "    ax[i].legend(title='Pretrained',loc='lower right', fontsize=18, title_fontsize=24)\n",
    "ax[0].get_legend().remove()\n",
    "# ax[0].set_ylim([0.4, 1.01])\n",
    "ax[1].get_legend().remove()\n",
    "# ax[1].set_ylim([0.4, 1.01])\n",
    "ax[2].get_legend().remove()\n",
    "ax[3].legend(title='Pretrained', fontsize=18, title_fontsize=24, loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rows, cols = 1, 3\n",
    "fig, ax = plt.subplots(rows, cols, figsize=(10*cols,6*rows))\n",
    "\n",
    "for i, y in enumerate([\"result.training_mean\", \"result.training_mean_de\", \"result.perturbation disentanglement\"]):\n",
    "    sns.violinplot(\n",
    "        data=best, \n",
    "        x=\"config.model.embedding.model\", \n",
    "        y=y, \n",
    "        hue='config.model.load_pretrained', \n",
    "        inner='points', \n",
    "        ax=ax[i], \n",
    "        scale='width',\n",
    "        )\n",
    "    ax[i].set_xticklabels(ax[i].get_xticklabels(), rotation=75, ha='right')\n",
    "    ax[i].set_xlabel('')\n",
    "    ax[i].set_ylabel(y.split('.')[-1])\n",
    "ax[0].get_legend().remove()\n",
    "ax[0].set_ylim([0.4, 1.01])\n",
    "ax[1].get_legend().remove()\n",
    "ax[1].set_ylim([0.4, 1.01])\n",
    "ax[2].legend(title='Pretrained', fontsize=18, title_fontsize=24, loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Take a deeper look in the `.config` of the best performing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "[c for c in best.columns if 'hash' in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "best[['config.model.load_pretrained', 'config_hash', 'result.test_mean_de', 'result.covariate disentanglement']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad25c9354f8cefdf5a943c25e67813a21d2807e3af4d6d0915e47390a83b57ce"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit ('chemical_CPA': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
